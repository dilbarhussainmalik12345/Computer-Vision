{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AV_Funny_jokes.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "0uOhyJM93NQ1",
        "gRxQcW1Q3NQ-",
        "tH25ShXu3NRU",
        "G5_53eHk3NRc",
        "c2yqFbMU3NSw"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navneetkrc/Colab_fastai/blob/master/AV_Funny_jokes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "bry8udXW3NQN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Was that Joke Funny??"
      ]
    },
    {
      "metadata": {
        "id": "8Ybu1h5T3Rrf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
        "!pip install fastai"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NC_wM3L63NQO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dPrbr9rG3NQS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from fastai import *\n",
        "from fastai.text import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a80Zz1nV3NQY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preparing the data"
      ]
    },
    {
      "metadata": {
        "id": "Uu4o8xwc3NQZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Many online businesses rely on customer reviews and ratings. Explicit feedback is especially important in the entertainment and ecommerce industry where all customer engagements are impacted by these ratings. Netflix relies on such rating data to power its recommendation engine to provide best movie and TV series recommendations that are personalized and most relevant to the user.\n",
        "\n",
        " \n",
        "\n",
        "This practice problem challenges the participants to predict the ratings for jokes given by the users provided the ratings provided by the same users for another set of jokes. This dataset is taken from the famous jester online Joke Recommender system dataset.\n",
        "\n",
        " \n",
        "\n",
        "We thank Dr. Ken Goldberg's group for putting this super cool data together and for permission to share it with the AV community. \n",
        "\n",
        "[Jester Funny Jokes](https://datahack.analyticsvidhya.com/contest/jester-practice-problem/)"
      ]
    },
    {
      "metadata": {
        "id": "P7Z-0bC-rltL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!mkdir data/train\n",
        "!mkdir data/test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XrLjfZajx_jn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://datahack.analyticsvidhya.com/contest/jester-practice-problem/download/test-file\n",
        "!wget https://datahack.analyticsvidhya.com/contest/jester-practice-problem/download/train-file\n",
        "!wget https://datahack.analyticsvidhya.com/contest/jester-practice-problem/download/sample-submission"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BbcsR5yGn3PL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#upload the files\n",
        "!unzip test.zip -d data/test\n",
        "!mv sample_submission.csv data\n",
        "!unzip train.zip -d data/train\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wKzJ5AUNoBe5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('data/train/train.csv')\n",
        "test = pd.read_csv('data/test/test.csv')\n",
        "jokes = pd.read_csv('data/train/jokes.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F_1oJMs83NQa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = 'data/'\n",
        "#!ls path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EvwIwMm9qrl2",
        "colab_type": "code",
        "outputId": "a4431af3-2ea5-4c43-fa8b-315c08e856a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "jokes.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>joke_id</th>\n",
              "      <th>joke_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Q. What's O. J. Simpson's web address? A. Slas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>How many feminists does it take to screw in a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Q. Did you hear about the dyslexic devil worsh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>They asked the Japanese visitor if they have e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Q: What did the blind person say when given so...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   joke_id                                          joke_text\n",
              "0        1  Q. What's O. J. Simpson's web address? A. Slas...\n",
              "1        2  How many feminists does it take to screw in a ...\n",
              "2        3  Q. Did you hear about the dyslexic devil worsh...\n",
              "3        4  They asked the Japanese visitor if they have e...\n",
              "4        5  Q: What did the blind person say when given so..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "4tqW5wei3NQh",
        "colab_type": "code",
        "outputId": "ea8e2471-f78f-4fce-fa3c-4458f74329cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "#train['joke_id'].value_counts()\n",
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>joke_id</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31030_110</td>\n",
              "      <td>31030</td>\n",
              "      <td>110</td>\n",
              "      <td>2.750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16144_109</td>\n",
              "      <td>16144</td>\n",
              "      <td>109</td>\n",
              "      <td>5.094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23098_6</td>\n",
              "      <td>23098</td>\n",
              "      <td>6</td>\n",
              "      <td>-6.438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14273_86</td>\n",
              "      <td>14273</td>\n",
              "      <td>86</td>\n",
              "      <td>4.406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18419_134</td>\n",
              "      <td>18419</td>\n",
              "      <td>134</td>\n",
              "      <td>9.375</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  user_id  joke_id  Rating\n",
              "0  31030_110    31030      110   2.750\n",
              "1  16144_109    16144      109   5.094\n",
              "2    23098_6    23098        6  -6.438\n",
              "3   14273_86    14273       86   4.406\n",
              "4  18419_134    18419      134   9.375"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "l4smIEoqqSz7",
        "colab_type": "code",
        "outputId": "726c0e37-1006-4fce-82d6-79a0ce7a7804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "train_df = pd.merge(train,jokes,on='joke_id')\n",
        "test_df = pd.merge(test,jokes[['joke_id', 'joke_text']],on='joke_id')\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>joke_id</th>\n",
              "      <th>Rating</th>\n",
              "      <th>joke_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31030_110</td>\n",
              "      <td>31030</td>\n",
              "      <td>110</td>\n",
              "      <td>2.750</td>\n",
              "      <td>Judy was having trouble with her computer, so ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9137_110</td>\n",
              "      <td>9137</td>\n",
              "      <td>110</td>\n",
              "      <td>1.719</td>\n",
              "      <td>Judy was having trouble with her computer, so ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27649_110</td>\n",
              "      <td>27649</td>\n",
              "      <td>110</td>\n",
              "      <td>5.031</td>\n",
              "      <td>Judy was having trouble with her computer, so ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35355_110</td>\n",
              "      <td>35355</td>\n",
              "      <td>110</td>\n",
              "      <td>3.031</td>\n",
              "      <td>Judy was having trouble with her computer, so ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5478_110</td>\n",
              "      <td>5478</td>\n",
              "      <td>110</td>\n",
              "      <td>3.094</td>\n",
              "      <td>Judy was having trouble with her computer, so ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  user_id  joke_id  Rating  \\\n",
              "0  31030_110    31030      110   2.750   \n",
              "1   9137_110     9137      110   1.719   \n",
              "2  27649_110    27649      110   5.031   \n",
              "3  35355_110    35355      110   3.031   \n",
              "4   5478_110     5478      110   3.094   \n",
              "\n",
              "                                           joke_text  \n",
              "0  Judy was having trouble with her computer, so ...  \n",
              "1  Judy was having trouble with her computer, so ...  \n",
              "2  Judy was having trouble with her computer, so ...  \n",
              "3  Judy was having trouble with her computer, so ...  \n",
              "4  Judy was having trouble with her computer, so ...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "dPxhskON_txx",
        "colab_type": "code",
        "outputId": "af9417c8-6191-47bc-b8d4-6024cb40920f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>joke_id</th>\n",
              "      <th>joke_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6194_11</td>\n",
              "      <td>6194</td>\n",
              "      <td>11</td>\n",
              "      <td>What's the difference between a used tire and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13494_11</td>\n",
              "      <td>13494</td>\n",
              "      <td>11</td>\n",
              "      <td>What's the difference between a used tire and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35167_11</td>\n",
              "      <td>35167</td>\n",
              "      <td>11</td>\n",
              "      <td>What's the difference between a used tire and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25066_11</td>\n",
              "      <td>25066</td>\n",
              "      <td>11</td>\n",
              "      <td>What's the difference between a used tire and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25103_11</td>\n",
              "      <td>25103</td>\n",
              "      <td>11</td>\n",
              "      <td>What's the difference between a used tire and ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  user_id  joke_id  \\\n",
              "0   6194_11     6194       11   \n",
              "1  13494_11    13494       11   \n",
              "2  35167_11    35167       11   \n",
              "3  25066_11    25066       11   \n",
              "4  25103_11    25103       11   \n",
              "\n",
              "                                           joke_text  \n",
              "0  What's the difference between a used tire and ...  \n",
              "1  What's the difference between a used tire and ...  \n",
              "2  What's the difference between a used tire and ...  \n",
              "3  What's the difference between a used tire and ...  \n",
              "4  What's the difference between a used tire and ...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "5kyhSy8mksfP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train_df['joke_id'].value_counts()\n",
        "train_df.rename(index=str, columns={\"joke_text\": \"text\", \"Rating\": \"target\"},inplace=True)\n",
        "test_df.rename(index=str, columns={\"joke_text\": \"text\"},inplace=True)\n",
        "jokes.rename(index=str, columns={\"joke_text\": \"text\"},inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7g7oLErenAGa",
        "colab_type": "code",
        "outputId": "653276c3-f5f2-44ff-aab4-3eaefeaa1b38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>joke_id</th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31030_110</td>\n",
              "      <td>31030</td>\n",
              "      <td>110</td>\n",
              "      <td>2.750</td>\n",
              "      <td>Judy was having trouble with her computer, so ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9137_110</td>\n",
              "      <td>9137</td>\n",
              "      <td>110</td>\n",
              "      <td>1.719</td>\n",
              "      <td>Judy was having trouble with her computer, so ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27649_110</td>\n",
              "      <td>27649</td>\n",
              "      <td>110</td>\n",
              "      <td>5.031</td>\n",
              "      <td>Judy was having trouble with her computer, so ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35355_110</td>\n",
              "      <td>35355</td>\n",
              "      <td>110</td>\n",
              "      <td>3.031</td>\n",
              "      <td>Judy was having trouble with her computer, so ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5478_110</td>\n",
              "      <td>5478</td>\n",
              "      <td>110</td>\n",
              "      <td>3.094</td>\n",
              "      <td>Judy was having trouble with her computer, so ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  user_id  joke_id  target  \\\n",
              "0  31030_110    31030      110   2.750   \n",
              "1   9137_110     9137      110   1.719   \n",
              "2  27649_110    27649      110   5.031   \n",
              "3  35355_110    35355      110   3.031   \n",
              "4   5478_110     5478      110   3.094   \n",
              "\n",
              "                                                text  \n",
              "0  Judy was having trouble with her computer, so ...  \n",
              "1  Judy was having trouble with her computer, so ...  \n",
              "2  Judy was having trouble with her computer, so ...  \n",
              "3  Judy was having trouble with her computer, so ...  \n",
              "4  Judy was having trouble with her computer, so ...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "kQo70AXRnCaD",
        "colab_type": "code",
        "outputId": "f6faa8a2-6af8-4863-97c3-7f28fd51e68f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>joke_id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6194_11</td>\n",
              "      <td>6194</td>\n",
              "      <td>11</td>\n",
              "      <td>What's the difference between a used tire and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13494_11</td>\n",
              "      <td>13494</td>\n",
              "      <td>11</td>\n",
              "      <td>What's the difference between a used tire and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35167_11</td>\n",
              "      <td>35167</td>\n",
              "      <td>11</td>\n",
              "      <td>What's the difference between a used tire and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25066_11</td>\n",
              "      <td>25066</td>\n",
              "      <td>11</td>\n",
              "      <td>What's the difference between a used tire and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25103_11</td>\n",
              "      <td>25103</td>\n",
              "      <td>11</td>\n",
              "      <td>What's the difference between a used tire and ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  user_id  joke_id  \\\n",
              "0   6194_11     6194       11   \n",
              "1  13494_11    13494       11   \n",
              "2  35167_11    35167       11   \n",
              "3  25066_11    25066       11   \n",
              "4  25103_11    25103       11   \n",
              "\n",
              "                                                text  \n",
              "0  What's the difference between a used tire and ...  \n",
              "1  What's the difference between a used tire and ...  \n",
              "2  What's the difference between a used tire and ...  \n",
              "3  What's the difference between a used tire and ...  \n",
              "4  What's the difference between a used tire and ...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "enSdoyVd3NQl",
        "colab_type": "code",
        "outputId": "a4998052-9a8c-4e60-816d-43b331f83562",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "train_df['text'][10000]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'One day the first grade teacher was reading the story of the Three Little Pigs to her class. She came to the part of the story where the first pig was trying to accumulate the building materials for his home. She read, \"...and so the pig went up to the man with the wheelbarrow full of straw and said, \\'Pardon me sir, but may I have some of that straw to build my house?\\'\" The teacher paused then asked the class, \"And what do you think that man said?\" One little boy raised his hand and said, \"I know...he said, \\'Holy Shit! A talking pig!\\'\"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "z5aJh3pr5ewv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a dataframe\n",
        "##df = pd.DataFrame({'label':train_df.Rating,\n",
        "##                   'text':train_df.joke_text})\n",
        "#this dataframe has a lot of duplicate questions need to remove that from the language model will check"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AXggF9g_SwDh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jhbmSVBt8R-V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#df.shape #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z4CfjYyn4VST",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train test split handled at FASTAI DATABLOCK Level\n",
        "#from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split data into training and validation set\n",
        "#df_trn, df_val = train_test_split(train_df, stratify = train_df['target'], test_size = 0.2, random_state = 12)\n",
        "#df_trn.shape, df_val.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MatRH2SC4deP",
        "colab_type": "code",
        "outputId": "df2c0738-6ac0-4263-dbde-ce3ca3465412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#df_trn.shape, df_val.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((873647, 5), (218412, 5))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "xDNGeuL5n7hX",
        "colab_type": "code",
        "outputId": "1cc4c723-b1f3-49b9-84b8-7bc8c3a6092a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "##Save the transformed Train and Test sets to csv for creating and executing Language models\n",
        "test_df.to_csv(f'test.csv', index=False)\n",
        "train_df.to_csv(f'train.csv', index=False)\n",
        "jokes.to_csv(f'jokes.csv', index=False)\n",
        "\n",
        "!mv test.csv data\\\n",
        "!mv train.csv data\\\n",
        "!mv jokes.csv data\\"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat 'data!mv': No such file or directory\n",
            "mv: cannot stat 'data!mv': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9iOJ2gza2E64",
        "colab_type": "code",
        "outputId": "6c415a8a-0908-4c82-94d6-df2619846441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "train_df.to_csv(f'train.csv', index=False)\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>joke_id</th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31030_110</td>\n",
              "      <td>31030</td>\n",
              "      <td>110</td>\n",
              "      <td>2.750</td>\n",
              "      <td>Judy was having trouble with her computer, so ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9137_110</td>\n",
              "      <td>9137</td>\n",
              "      <td>110</td>\n",
              "      <td>1.719</td>\n",
              "      <td>Judy was having trouble with her computer, so ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27649_110</td>\n",
              "      <td>27649</td>\n",
              "      <td>110</td>\n",
              "      <td>5.031</td>\n",
              "      <td>Judy was having trouble with her computer, so ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35355_110</td>\n",
              "      <td>35355</td>\n",
              "      <td>110</td>\n",
              "      <td>3.031</td>\n",
              "      <td>Judy was having trouble with her computer, so ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5478_110</td>\n",
              "      <td>5478</td>\n",
              "      <td>110</td>\n",
              "      <td>3.094</td>\n",
              "      <td>Judy was having trouble with her computer, so ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  user_id  joke_id  target  \\\n",
              "0  31030_110    31030      110   2.750   \n",
              "1   9137_110     9137      110   1.719   \n",
              "2  27649_110    27649      110   5.031   \n",
              "3  35355_110    35355      110   3.031   \n",
              "4   5478_110     5478      110   3.094   \n",
              "\n",
              "                                                text  \n",
              "0  Judy was having trouble with her computer, so ...  \n",
              "1  Judy was having trouble with her computer, so ...  \n",
              "2  Judy was having trouble with her computer, so ...  \n",
              "3  Judy was having trouble with her computer, so ...  \n",
              "4  Judy was having trouble with her computer, so ...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "ocyquSFvzd0V",
        "colab_type": "code",
        "outputId": "53bacb38-f604-44bc-c248-120ded7af48f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "jokes.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>joke_id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Q. What's O. J. Simpson's web address? A. Slas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>How many feminists does it take to screw in a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Q. Did you hear about the dyslexic devil worsh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>They asked the Japanese visitor if they have e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Q: What did the blind person say when given so...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   joke_id                                               text\n",
              "0        1  Q. What's O. J. Simpson's web address? A. Slas...\n",
              "1        2  How many feminists does it take to screw in a ...\n",
              "2        3  Q. Did you hear about the dyslexic devil worsh...\n",
              "3        4  They asked the Japanese visitor if they have e...\n",
              "4        5  Q: What did the blind person say when given so..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "Ibl1MOw5oQnM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path_working = Path('data/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xnphTBq21Xa4",
        "colab_type": "code",
        "outputId": "bf7e2d20-cdd5-4903-b231-744b328c6f93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "cell_type": "code",
      "source": [
        "path = 'data/'\n",
        "data_lm = TextLMDataBunch.from_csv(path, 'jokes.csv')\n",
        "x,y = next(iter(data.train_dl))\n",
        "example = x[:15,:15].cpu()\n",
        "texts = pd.DataFrame([data.train_ds.vocab.textify(l).split(' ') for l in example])\n",
        "texts"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos</td>\n",
              "      <td>a</td>\n",
              "      <td>xxunk</td>\n",
              "      <td>walks</td>\n",
              "      <td>into</td>\n",
              "      <td>a</td>\n",
              "      <td>bar</td>\n",
              "      <td>and</td>\n",
              "      <td>orders</td>\n",
              "      <td>a</td>\n",
              "      <td>drink</td>\n",
              "      <td>.</td>\n",
              "      <td>\"</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>how</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>.</td>\n",
              "      <td>(</td>\n",
              "      <td>xxunk</td>\n",
              "      <td>)</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>the</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>xxunk</td>\n",
              "      <td>drink</td>\n",
              "      <td>very</td>\n",
              "      <td>little</td>\n",
              "      <td>red</td>\n",
              "      <td>wine</td>\n",
              "      <td>and</td>\n",
              "      <td>suffer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>saved</td>\n",
              "      <td>.</td>\n",
              "      <td>\"</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>the</td>\n",
              "      <td>second</td>\n",
              "      <td>man</td>\n",
              "      <td>went</td>\n",
              "      <td>up</td>\n",
              "      <td>to</td>\n",
              "      <td>the</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>father</td>\n",
              "      <td>...</td>\n",
              "      <td>xxmaj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>xxunk</td>\n",
              "      <td>and</td>\n",
              "      <td>xxunk</td>\n",
              "      <td>the</td>\n",
              "      <td>problem</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>as</td>\n",
              "      <td>he</td>\n",
              "      <td>was</td>\n",
              "      <td>walking</td>\n",
              "      <td>away</td>\n",
              "      <td>,</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>judy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>xxbos</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>bill</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>clinton</td>\n",
              "      <td>xxunk</td>\n",
              "      <td>from</td>\n",
              "      <td>a</td>\n",
              "      <td>vacation</td>\n",
              "      <td>in</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>xxunk</td>\n",
              "      <td>and</td>\n",
              "      <td>walks</td>\n",
              "      <td>down</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>xxunk</td>\n",
              "      <td>,</td>\n",
              "      <td>so</td>\n",
              "      <td>we</td>\n",
              "      <td>'ll</td>\n",
              "      <td>call</td>\n",
              "      <td>you</td>\n",
              "      <td>the</td>\n",
              "      <td>people</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>the</td>\n",
              "      <td>nanny</td>\n",
              "      <td>,</td>\n",
              "      <td>we</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>his</td>\n",
              "      <td>father</td>\n",
              "      <td>,</td>\n",
              "      <td>\"</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>dad</td>\n",
              "      <td>,</td>\n",
              "      <td>i</td>\n",
              "      <td>think</td>\n",
              "      <td>i</td>\n",
              "      <td>xxunk</td>\n",
              "      <td>the</td>\n",
              "      <td>xxunk</td>\n",
              "      <td>of</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>xxunk</td>\n",
              "      <td>it</td>\n",
              "      <td>is</td>\n",
              "      <td>xxunk</td>\n",
              "      <td>he</td>\n",
              "      <td>is</td>\n",
              "      <td>asked</td>\n",
              "      <td>to</td>\n",
              "      <td>xxunk</td>\n",
              "      <td>for</td>\n",
              "      <td>xxunk</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>when</td>\n",
              "      <td>he</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>bill</td>\n",
              "      <td>says</td>\n",
              "      <td>,</td>\n",
              "      <td>\"</td>\n",
              "      <td>i</td>\n",
              "      <td>could</td>\n",
              "      <td>throw</td>\n",
              "      <td>one</td>\n",
              "      <td>xxunk</td>\n",
              "      <td>-</td>\n",
              "      <td>dollar</td>\n",
              "      <td>bill</td>\n",
              "      <td>out</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>xxunk</td>\n",
              "      <td>is</td>\n",
              "      <td>xxunk</td>\n",
              "      <td>!</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>what</td>\n",
              "      <td>can</td>\n",
              "      <td>i</td>\n",
              "      <td>do</td>\n",
              "      <td>?</td>\n",
              "      <td>\"</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>the</td>\n",
              "      <td>xxunk</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>the</td>\n",
              "      <td>engineer</td>\n",
              "      <td>is</td>\n",
              "      <td>a</td>\n",
              "      <td>xxunk</td>\n",
              "      <td>xxunk</td>\n",
              "      <td>guy</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>one</td>\n",
              "      <td>day</td>\n",
              "      <td>,</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>god</td>\n",
              "      <td>xxunk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>,</td>\n",
              "      <td>right</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>and</td>\n",
              "      <td>just</td>\n",
              "      <td>where</td>\n",
              "      <td>are</td>\n",
              "      <td>xxup</td>\n",
              "      <td>you</td>\n",
              "      <td>going</td>\n",
              "      <td>to</td>\n",
              "      <td>get</td>\n",
              "      <td>a</td>\n",
              "      <td>xxunk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>on</td>\n",
              "      <td>the</td>\n",
              "      <td>second</td>\n",
              "      <td>floor</td>\n",
              "      <td>reads</td>\n",
              "      <td>:</td>\n",
              "      <td>\"</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>all</td>\n",
              "      <td>the</td>\n",
              "      <td>men</td>\n",
              "      <td>here</td>\n",
              "      <td>are</td>\n",
              "      <td>xxunk</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>please</td>\n",
              "      <td>a</td>\n",
              "      <td>woman</td>\n",
              "      <td>.</td>\n",
              "      <td>\"</td>\n",
              "      <td>xxbos</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>two</td>\n",
              "      <td>xxunk</td>\n",
              "      <td>went</td>\n",
              "      <td>into</td>\n",
              "      <td>a</td>\n",
              "      <td>xxunk</td>\n",
              "      <td>and</td>\n",
              "      <td>xxunk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>xxunk</td>\n",
              "      <td>xxunk</td>\n",
              "      <td>xxunk</td>\n",
              "      <td>,</td>\n",
              "      <td>then</td>\n",
              "      <td>down</td>\n",
              "      <td>at</td>\n",
              "      <td>her</td>\n",
              "      <td>xxunk</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>she</td>\n",
              "      <td>took</td>\n",
              "      <td>a</td>\n",
              "      <td>few</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1       2      3        4       5      6      7         8   \\\n",
              "0    xxbos         a   xxunk  walks     into       a    bar    and    orders   \n",
              "1        .         (   xxunk      )    xxmaj     the  xxmaj  xxunk     drink   \n",
              "2    saved         .       \"  xxmaj      the  second    man   went        up   \n",
              "3    xxunk       and   xxunk    the  problem       .  xxmaj     as        he   \n",
              "4    xxbos     xxmaj    bill  xxmaj  clinton   xxunk   from      a  vacation   \n",
              "5    xxunk         ,      so     we      'll    call    you    the    people   \n",
              "6      his    father       ,      \"    xxmaj     dad      ,      i     think   \n",
              "7    xxunk        it      is  xxunk       he      is  asked     to     xxunk   \n",
              "8        .     xxmaj    bill   says        ,       \"      i  could     throw   \n",
              "9    xxunk        is   xxunk      !    xxmaj    what    can      i        do   \n",
              "10     the  engineer      is      a    xxunk   xxunk    guy      .     xxmaj   \n",
              "11       ,     right       .  xxmaj      and    just  where    are      xxup   \n",
              "12      on       the  second  floor    reads       :      \"  xxmaj       all   \n",
              "13  please         a   woman      .        \"   xxbos  xxmaj    two     xxunk   \n",
              "14   xxunk     xxunk   xxunk      ,     then    down     at    her     xxunk   \n",
              "\n",
              "      9        10     11      12     13        14  \n",
              "0      a    drink      .       \"  xxmaj       how  \n",
              "1   very   little    red    wine    and    suffer  \n",
              "2     to      the  xxmaj  father    ...     xxmaj  \n",
              "3    was  walking   away       ,  xxmaj      judy  \n",
              "4     in    xxmaj  xxunk     and  walks      down  \n",
              "5      .    xxmaj    the   nanny      ,        we  \n",
              "6      i    xxunk    the   xxunk     of  politics  \n",
              "7    for    xxunk      .   xxmaj   when        he  \n",
              "8    one    xxunk      -  dollar   bill       out  \n",
              "9      ?        \"  xxmaj     the  xxunk         ,  \n",
              "10   one      day      ,   xxmaj    god     xxunk  \n",
              "11   you    going     to     get      a     xxunk  \n",
              "12   the      men   here     are  xxunk       and  \n",
              "13  went     into      a   xxunk    and     xxunk  \n",
              "14     .    xxmaj    she    took      a       few  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "fymNTOZ9pH1U",
        "colab_type": "code",
        "outputId": "df016380-8a68-4746-a7af-4c206aa2f26a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "cell_type": "code",
      "source": [
        "learn = language_model_learner(data_lm, pretrained_model=URLs.WT103, drop_mult=0.7)\n",
        "learn.model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialRNN(\n",
              "  (0): RNNCore(\n",
              "    (encoder): Embedding(508, 400, padding_idx=1)\n",
              "    (encoder_dp): EmbeddingDropout(\n",
              "      (emb): Embedding(508, 400, padding_idx=1)\n",
              "    )\n",
              "    (rnns): ModuleList(\n",
              "      (0): WeightDropout(\n",
              "        (module): LSTM(400, 1150, batch_first=True)\n",
              "      )\n",
              "      (1): WeightDropout(\n",
              "        (module): LSTM(1150, 1150, batch_first=True)\n",
              "      )\n",
              "      (2): WeightDropout(\n",
              "        (module): LSTM(1150, 400, batch_first=True)\n",
              "      )\n",
              "    )\n",
              "    (input_dp): RNNDropout()\n",
              "    (hidden_dps): ModuleList(\n",
              "      (0): RNNDropout()\n",
              "      (1): RNNDropout()\n",
              "      (2): RNNDropout()\n",
              "    )\n",
              "  )\n",
              "  (1): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=508, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "RE1e1MwVpNQ7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xa662_ybpOnz",
        "colab_type": "code",
        "outputId": "094ac0eb-c797-47b7-a3c1-a879b4bb2cde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "cell_type": "code",
      "source": [
        "learn.recorder.plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEGCAYAAABsLkJ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fdee06bcc50>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "FFfvqs3BpOiz",
        "colab_type": "code",
        "outputId": "d53f1cb2-2779-4b49-c37f-cb447bc9a0ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(10, 1e-2)\n",
        "learn.save('mini_train_lm')\n",
        "learn.save_encoder('mini_train_encoder')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Total time: 00:07 <p><table style='width:300px; margin-bottom:10px'>\n",
              "  <tr>\n",
              "    <th>epoch</th>\n",
              "    <th>train_loss</th>\n",
              "    <th>valid_loss</th>\n",
              "    <th>accuracy</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>1</th>\n",
              "    <th>4.714853</th>\n",
              "    <th>4.134651</th>\n",
              "    <th>0.285342</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>2</th>\n",
              "    <th>4.668473</th>\n",
              "    <th>4.079427</th>\n",
              "    <th>0.292039</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>3</th>\n",
              "    <th>4.628178</th>\n",
              "    <th>3.969118</th>\n",
              "    <th>0.292783</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>4</th>\n",
              "    <th>4.561645</th>\n",
              "    <th>3.851142</th>\n",
              "    <th>0.303571</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>5</th>\n",
              "    <th>4.481604</th>\n",
              "    <th>3.772702</th>\n",
              "    <th>0.302827</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>6</th>\n",
              "    <th>4.411114</th>\n",
              "    <th>3.771942</th>\n",
              "    <th>0.303646</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>7</th>\n",
              "    <th>4.338284</th>\n",
              "    <th>3.662111</th>\n",
              "    <th>0.312128</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>8</th>\n",
              "    <th>4.278879</th>\n",
              "    <th>3.624386</th>\n",
              "    <th>0.318824</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>9</th>\n",
              "    <th>4.237555</th>\n",
              "    <th>3.611463</th>\n",
              "    <th>0.315476</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>10</th>\n",
              "    <th>4.189270</th>\n",
              "    <th>3.592975</th>\n",
              "    <th>0.311012</th>\n",
              "  </tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "4jOFrROmpObi",
        "colab_type": "code",
        "outputId": "127e6baa-98e7-4582-eb25-f65d22fac94b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "cell_type": "code",
      "source": [
        "learn.show_results()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table>  <col width='34%'>  <col width='33%'>  <col width='33%'>  <tr>\n",
              "    <th>text</th>\n",
              "    <th>target</th>\n",
              "    <th>pred</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>xxbos xxmaj did you xxunk about the xxmaj xxunk who xxunk xxmaj xxunk xxunk a xxunk xxunk ? xxmaj he</th>\n",
              "    <th>to xxunk xxunk xxunk . xxbos xxmaj what is the xxunk xxunk of the xxmaj xxunk xxmaj xxunk xxmaj xxunk</th>\n",
              "    <th>xxunk xxunk xxunk xxunk xxunk xxunk xxbos xxunk xxunk the xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>xxmaj xxunk xxmaj xxunk ! xxbos xxmaj what do you get when you xxunk over a xxunk with a xxunk</th>\n",
              "    <th>xxmaj xxunk xxunk . xxbos xxmaj an old man goes to the doctor for his xxunk xxunk , his wife</th>\n",
              "    <th>xxunk xxunk xxunk xxunk xxunk xxbos xxunk engineer man xxunk to xxunk xxunk and a xxunk . . and xxunk</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>. xxmaj when the doctor xxunk the xxunk room , he tells the old man , \" i need a</th>\n",
              "    <th>xxunk , a xxunk xxunk and a xxunk xxunk . \" xxmaj the old man , being xxunk of xxunk</th>\n",
              "    <th>. . and xxunk xxunk , a xxunk xxunk . \" the xxunk xxunk man says xxunk xxunk , the</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>at his wife and xxunk : \" xxup what ? xxmaj what did he say ? xxmaj what 's he</th>\n",
              "    <th>? \" xxmaj his wife xxunk back , \" xxmaj he xxunk your xxunk . \" xxbos a lawyer xxunk</th>\n",
              "    <th>? \" \" xxunk mother xxunk xxunk to \" xxunk xxunk 's xxunk xxunk . \" \" xxfld xxunk asked</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>of his xxup xxunk , when xxunk a car xxunk xxunk and xxunk the door , xxunk it off xxunk</th>\n",
              "    <th>xxmaj when the xxunk xxunk at the xxunk , the lawyer was xxunk xxunk about the xxunk to his xxunk</th>\n",
              "    <th>\" xxunk he xxunk xxunk xxunk the xxunk xxunk xxunk xxunk xxunk xxunk . . the xxunk xxunk xxunk xxunk</th>\n",
              "  </tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "qAQ4m7H9pOel",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##load the encoder models in models folder and load the model encoder\n",
        "#!mkdir data/models\n",
        "#!mv mini_train_encoder.pth data/models/\n",
        "#!mv mini_train_lm.pth data/models/\n",
        "#learn.load_encoder('mini_train_encoder')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0if2oK1GyZ3Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Word Embeddings\n",
        "\n",
        "[word-embedding-word2vec-explained](https://www.knime.com/blog/word-embedding-word2vec-explained)\n",
        "\n",
        "[word-embeddings-exploration-explanation-and-exploitation](https://towardsdatascience.com/word-embeddings-exploration-explanation-and-exploitation-with-code-in-python-5dac99d5d795)\n",
        "\n",
        "[AV word-embeddings-count-word2veec](https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/)"
      ]
    },
    {
      "metadata": {
        "id": "NzD2gd6fyZ_w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "ewRKcAk0pOYa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#classifier\n",
        "path = 'data/'\n",
        "data = TextClasDataBunch.from_csv(path, 'train.csv')\n",
        "iter_dl = iter(data.train_dl)\n",
        "_ = next(iter_dl)\n",
        "x,y = next(iter_dl)\n",
        "x[-10:,:20]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yAexyne7pOVP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Language model data\n",
        "data_lm = (TextList.from_csv(path_working, 'jokes.csv', cols='text') \n",
        "                   .random_split_by_pct()\n",
        "                   .databunch(bs=256))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gEnwQ6napOR1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Language model data\n",
        "data_lm = (TextList.from_csv(path_working, 'train.csv', cols='text') \n",
        "                   .random_split_by_pct()\n",
        "                   .label_for_lm()\n",
        "                   .add_test(TextList.from_csv(path_working, 'test.csv', cols='text'))\n",
        "                   .databunch(bs=256))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AxOxNEKkpNOK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Classifier model data\n",
        "\n",
        "data_clas = (TextList.from_csv(path_working, 'train.csv',cols='text', vocab=data_lm.vocab)\n",
        "    .split_from_df(col='is_valid') #is_valid\n",
        "    .label_from_df(cols='target')\n",
        "    .add_test(TextList.from_csv(path_working, 'test.csv', cols='text'))\n",
        "    .databunch(bs=42))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BKAgmYk_4jRE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Classifier model data\n",
        "#data_clas = TextClasDataBunch.from_df(path = \"\", train_df = df_trn, valid_df = df_val, vocab=data_lm.train_ds.vocab, bs=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xXmn-7aO3NQp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It contains one line per review, with the Rating (numerical value), the text and a flag to determine if it should be part of the validation set or the training set. If we ignore this flag, we can create a DataBunch containing this data in one line of code:"
      ]
    },
    {
      "metadata": {
        "id": "RrjD5men4t_E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train the learner object\n",
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YD5fhyiG3NQq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#data_lm = TextDataBunch.from_csv(path='data/',csv_name='jokes.csv')\n",
        "#data_lm = TextDataBunch.from_df(path, 'train_df', text_cols='joke_text',label_cols='Rating')\n",
        "#data_lm = (TextList.from_folder(path='data/')\n",
        "           #Inputs: all the text files in path\n",
        "#            .filter_by_folder(include=['train', 'test']) \n",
        "           #We may have other temp folders that contain text files so we only keep what's in train and test\n",
        "#            .random_split_by_pct(0.1)\n",
        "           #We randomly split and keep 10% (10,000 reviews) for validation\n",
        "#            .label_for_lm()           \n",
        "           #We want to do a language model so we label accordingly\n",
        "#            .databunch(bs=48))\n",
        "data_lm.save('tmp_lm')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TZRuKQ203NQu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "By executing this line a process was launched that took a bit of time. Let's dig a bit into it. Images could be fed (almost) directly into a model because they're just a big array of pixel values that are floats between 0 and 1. A text is composed of words, and we can't apply mathematical functions to them directly. We first have to convert them to numbers. This is done in two differents steps: tokenization and numericalization. A `TextDataBunch` does all of that behind the scenes for you.\n",
        "\n",
        "Before we delve into the explanations, let's take the time to save the things that were calculated."
      ]
    },
    {
      "metadata": {
        "id": "uE_h0mKO3NQu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_lm.save()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z2JFnGLQ3NQy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next time we launch this notebook, we can skip the cell above that took a bit of time (and that will take a lot more when you get to the full dataset) and load those results like this:"
      ]
    },
    {
      "metadata": {
        "id": "QF5TK-0c3NQy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = TextDataBunch.load(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0uOhyJM93NQ1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tokenization"
      ]
    },
    {
      "metadata": {
        "id": "bMxXykhQ3NQ3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The first step of processing we make texts go through is to split the raw sentences into words, or more exactly tokens. The easiest way to do this would be to split the string on spaces, but we can be smarter:\n",
        "\n",
        "- we need to take care of punctuation\n",
        "- some words are contractions of two different words, like isn't or don't\n",
        "- we may need to clean some parts of our texts, if there's HTML code for instance\n",
        "\n",
        "To see what the tokenizer had done behind the scenes, let's have a look at a few texts in a batch."
      ]
    },
    {
      "metadata": {
        "id": "mjsLdz873NQ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = TextClasDataBunch.load(path)\n",
        "data.show_batch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "euO0pkh83NQ9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The texts are truncated at 100 tokens for more readability. We can see that it did more than just split on space and punctuation symbols: \n",
        "- the \"'s\" are grouped together in one token\n",
        "- the contractions are separated like his: \"did\", \"n't\"\n",
        "- content has been cleaned for any HTML symbol and lower cased\n",
        "- there are several special tokens (all those that begin by xx), to replace unkown tokens (see below) or to introduce different text fields (here we only have one)."
      ]
    },
    {
      "metadata": {
        "id": "gRxQcW1Q3NQ-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Numericalization"
      ]
    },
    {
      "metadata": {
        "id": "-dHwyPhD3NQ-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Once we have extracted tokens from our texts, we convert to integers by creating a list of all the words used. We only keep the ones that appear at list twice with a maximum vocabulary size of 60,000 (by default) and replace the ones that don't make the cut by the unknown token `UNK`.\n",
        "\n",
        "The correspondance from ids tokens is stored in the `vocab` attribute of our datasets, in a dictionary called `itos` (for int to string)."
      ]
    },
    {
      "metadata": {
        "id": "f0Xb99IE3NRA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data.vocab.itos[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "35ue3Umm3NRE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And if we look at what a what's in our datasets, we'll see the tokenized text as a representation:"
      ]
    },
    {
      "metadata": {
        "id": "mr5vKxhU3NRF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data.train_ds[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "19NmtmOJ3NRN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "But the underlying data is all numbers"
      ]
    },
    {
      "metadata": {
        "id": "KvJvNJPx3NRP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data.train_ds[0][0].data[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tH25ShXu3NRU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### With the data block API"
      ]
    },
    {
      "metadata": {
        "id": "vOiPjgjm3NRU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can use the data block API with NLP and have a lot more flexibility than what the default factory methods offer. In the previous example for instance, the data was randomly split between train and validation instead of reading the third column of the csv.\n",
        "\n",
        "With the data block API though, we have to manually call the tokenize and numericalize steps. This allows more flexibility, and if you're not using the defaults from fastai, the variaous arguments to pass will appear in the step they're revelant, so it'll be more readable."
      ]
    },
    {
      "metadata": {
        "id": "6yPHDF5-3NRZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = (TextList.from_csv(path, 'texts.csv', cols='text')\n",
        "                .split_from_df(col=2)\n",
        "                .label_from_df(cols=0)\n",
        "                .databunch())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_p4VR7HRnxhD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Word Embeddings \n",
        "Working on Text Data to derive the wisdom from words. \n"
      ]
    },
    {
      "metadata": {
        "id": "rqE0VIUiwOKf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[word-embedding-word2vec-explained](https://www.knime.com/blog/word-embedding-word2vec-explained)\n",
        "\n",
        "[word-embeddings-exploration-explanation-and-exploitation](https://towardsdatascience.com/word-embeddings-exploration-explanation-and-exploitation-with-code-in-python-5dac99d5d795)\n",
        "\n",
        "[AV word-embeddings-count-word2veec](https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/)"
      ]
    },
    {
      "metadata": {
        "id": "oPb0k7C9oC1x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Analytics Vidhya Explanation to word embeddings:-\n",
        "\n",
        "In very simplistic terms, **Word Embeddings are the texts converted into numbers and there may be different numerical representations of the same text.**\n",
        "\n",
        "As it turns out in many Machine Learning algorithms and almost all Deep Learning Architectures are incapable of processing strings or plain text in their raw form. They require numbers as inputs to perform any sort of job, be it classification, regression etc.\n",
        "\n",
        "####Different types of Word Embeddings\n",
        " *  Frequency based Embedding\n",
        " * Count Vectors\n",
        " * TF-IDF\n",
        " * Co-Occurrence Matrix\n",
        " * Prediction based Embedding\n",
        " * CBOW\n",
        " * Skip-Gram\n",
        "\n",
        "####Different types of Word Embeddings\n",
        "The different types of word embeddings can be broadly classified into two categories-\n",
        "\n",
        "**Frequency based Embedding**\n",
        "\n",
        "**Prediction based Embedding**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "sJ-YVv-1r6Qg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Frequency based Embedding**\n",
        "\n",
        "1.   Count Vector (Unique tokens from the corpus to form our dictionary)\n",
        "\n",
        "2.   TF-IDF Vector (it takes into account not just the occurrence of a word in a single document but in the entire corpus. Ideally, what we would want is to down weight the common words occurring in almost all documents and give more importance to words that appear in a subset of documents.)\n",
        "\n",
        "3.   Co-Occurrence Vector(**The big idea** – Similar words tend to occur together and will have similar context for example – Apple is a fruit. Mango is a fruit.)\n",
        "\n",
        "**Advantages of Co-occurrence Matrix**\n",
        "\n",
        "It preserves the semantic relationship between words. i.e man and woman tend to be closer than man and apple.\n",
        "\n",
        "It uses SVD at its core, which produces more accurate word vector representations than existing methods.\n",
        "\n",
        "It uses factorization which is a well-defined problem and can be efficiently solved.\n",
        "\n",
        "It has to be computed once and can be used anytime once computed. In this sense, it is faster in comparison to others.\n",
        " \n",
        "\n",
        "**Disadvantages of Co-Occurrence Matrix**\n",
        "\n",
        "It requires huge memory to store the co-occurrence matrix.\n",
        "\n",
        "But, this problem can be circumvented by factorizing the matrix out of the system for example in Hadoop clusters etc. and can be saved.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "wH7b7b4nr-PY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Prediction based Embedding**\n",
        "\n",
        "\n",
        "*   CBOW\n",
        "*   Skip-Gram\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**CBOW (Continuous Bag of words)**\n",
        "\n",
        "The way CBOW work is that it tends to predict the probability of a word given a context. A context may be a single word or a group of words. But for simplicity, I will take a single context word and try to predict a single target word.\n",
        "\n",
        "**Advantages of CBOW:**\n",
        "\n",
        "Being probabilistic is nature, it is supposed to perform superior to deterministic methods(generally).\n",
        "\n",
        "It is low on memory. It does not need to have huge RAM requirements like that of co-occurrence matrix where it needs to store three huge matrices.\n",
        " \n",
        "\n",
        "**Disadvantages of CBOW:**\n",
        "\n",
        "CBOW takes the average of the context of a word (as seen above in calculation of hidden activation). For example, Apple can be both a fruit and a company but CBOW takes an average of both the contexts and places it in between a cluster for fruits and companies.\n",
        "\n",
        "Training a CBOW from scratch can take forever if not properly optimized.\n",
        "\n",
        "\n",
        "**Skip-Gram Model**\n",
        "\n",
        "Skip – gram follows the same topology as of CBOW. It just flips CBOW’s architecture on its head. The aim of skip-gram is to predict the context given a word.\n",
        "\n",
        " \n"
      ]
    },
    {
      "metadata": {
        "id": "G5_53eHk3NRc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Language model"
      ]
    },
    {
      "metadata": {
        "id": "bqWZxv_J3NRd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's grab the full dataset for what follows."
      ]
    },
    {
      "metadata": {
        "id": "mj7OBl4_3NRe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = untar_data(URLs.IMDB)\n",
        "path.ls()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O9cdi_0Y3NRh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(path/'train').ls()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BAiuhwdi3NRl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The reviews are in a training and test set following an imagenet structure. The only difference is that there is an `unsup` folder in `train` that contains the unlabelled data.\n",
        "\n",
        "We're not going to train a model that classifies the reviews from scratch. Like in computer vision, we'll use a model pretrained on a bigger dataset (a cleaned subset of wikipeia called [wikitext-103](https://einstein.ai/research/blog/the-wikitext-long-term-dependency-language-modeling-dataset)). That model has been trained to guess what the next word, its input being all the previous words. It has a recurrent structure and a hidden state that is updated each time it sees a new word. This hidden state thus contains information about the sentence up to that point.\n",
        "\n",
        "We are going to use that 'knowledge' of the English language to build our classifier, but first, like for computer vision, we need to fine-tune the pretrained model to our particular dataset. Because the English of the reviex lefts by people on IMDB isn't the same as the English of wikipedia, we'll need to adjust a little bit the parameters of our model. Plus there might be some words extremely common in that dataset that were barely present in wikipedia, and therefore might no be part of the vocabulary the model was trained on.\n",
        "\n",
        "Note that language models can use a lot of GPU, so you may need to decrease batchsize here."
      ]
    },
    {
      "metadata": {
        "id": "t0UJOdg43NRo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is where the unlabelled data is going to be useful to us, as we can use it to fine-tune our model. Let's create our data object with the data block API (next line takes a few minutes)."
      ]
    },
    {
      "metadata": {
        "id": "xbhCtguo3NRn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bs=32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FkSZuFSr3NRp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_lm = (TextList.from_folder(path)\n",
        "           #Inputs: all the text files in path\n",
        "            .filter_by_folder(include=['train', 'test']) \n",
        "           #We may have other temp folders that contain text files so we only keep what's in train and test\n",
        "            .random_split_by_pct(0.1)\n",
        "           #We randomly split and keep 10% (10,000 reviews) for validation\n",
        "            .label_for_lm()           \n",
        "           #We want to do a language model so we label accordingly\n",
        "            .databunch(bs=bs))\n",
        "data_lm.save('tmp_lm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ueTneGT3NRt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have to use a special kind of `TextDataBunch` for the language model, that ignores the labels (that's why we put 0 everywhere), will shuffle the texts at each epoch before concatenating them all together (only for training, we don't shuffle for the validation set) and will send batches that read that text in order with targets that are the next word in the sentence.\n",
        "\n",
        "The line before being a bit long, we want to load quickly the final ids by using the following cell."
      ]
    },
    {
      "metadata": {
        "id": "mn9-IS5E3NRt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_lm = TextLMDataBunch.load(path, 'tmp_lm', bs=bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yak4dKpl3NRw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_lm.show_batch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hZHH-Dh73NR3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can then put this in a learner object very easily with a model loaded with the pretrained weights. They'll be downloaded the first time you'll execute the following line and stored in './fastai/models/' (or elsewhere if you specified different paths in your config file)."
      ]
    },
    {
      "metadata": {
        "id": "_xYeeXJl3NR4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn = language_model_learner(data_lm, pretrained_model=URLs.WT103_1, drop_mult=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BuqTnWDO3NR8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rmbrEAWk3NSC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.recorder.plot(skip_end=15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F6pm9AKN3NSF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iEq4kiSXW0aE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Total time: 1:24:10\n",
        "\n",
        "epoch\ttrain_loss\tvalid_loss\taccuracy\n",
        "\n",
        "1\t4.198589\t4.057909\t0.294069\n"
      ]
    },
    {
      "metadata": {
        "id": "Q5Au13003NSJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('fit_head')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uc9M2sSV3NSL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.load('fit_head');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "73rRtdBr3NSO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To complete the fine-tuning, we can then unfeeze and launch a new training."
      ]
    },
    {
      "metadata": {
        "id": "69F-Gmv53NSP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(20, 1e-3, moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FnyUygYo3NSS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('fine_tuned')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WUm8kyZx3NSV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "How good is our model? Well let's try to see what it predicts after a few given words."
      ]
    },
    {
      "metadata": {
        "id": "2MPrc6Ic3NSW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.load('fine_tuned');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WCKDvJFZ3NSg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TEXT = \"i liked this movie because\"\n",
        "N_WORDS = 40\n",
        "N_SENTENCES = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x2zTP_Bh3NSl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"\\n\".join(learn.predict(TEXT, N_WORDS) for _ in range(N_SENTENCES)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MrM6lFdL3NSr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have to save the model but also it's encoder, the part that's responsible for creating and updating the hidden state. For the next part, we don't care about the part that tries to guess the next word."
      ]
    },
    {
      "metadata": {
        "id": "mztPHQZw3NSs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save_encoder('fine_tuned_enc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c2yqFbMU3NSw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Classifier"
      ]
    },
    {
      "metadata": {
        "id": "nWIOxKlG3NSw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, we'll create a new data object that only grabs the labelled data and keeps those labels. Again, this line takes a bit of time."
      ]
    },
    {
      "metadata": {
        "id": "HIqEJo163NSy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = untar_data(URLs.IMDB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SbHqIvAK3NS1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_clas = (TextList.from_folder(path, vocab=data_lm.vocab)\n",
        "             #grab all the text files in path\n",
        "             .split_by_folder(valid='test')\n",
        "             #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n",
        "             .label_from_folder(classes=['neg', 'pos'])\n",
        "             #remove docs with labels not in above list (i.e. 'unsup')\n",
        "             .filter_missing_y()\n",
        "             #label them all with their folders\n",
        "             .databunch(bs=bs))\n",
        "data_clas.save('tmp_clas')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lcRwKZ0X3NS6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(data_clas.train_ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JG6THlbW3NS_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_clas = TextClasDataBunch.load(path, 'tmp_clas', bs=bs)\n",
        "data_clas.show_batch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EGldEOpW3NTE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can then create a model to classify those reviews and load the encoder we saved before."
      ]
    },
    {
      "metadata": {
        "id": "lTj72fFO3NTG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn = text_classifier_learner(data_clas, drop_mult=0.5)\n",
        "learn.load_encoder('fine_tuned_enc')\n",
        "learn.freeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pab-A1AH3NTK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9VzWsmcx3NTS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.recorder.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5ssDdm3q3NTW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X9HqH3J33NTa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('first')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AJyc9Jdl3NTg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.load('first');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-e-mEPyi3NTj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.freeze_to(-2)\n",
        "learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RuaYOzQi3NTp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('second')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RfNMP3zD3NTt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.load('second');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yOCISJim3NTy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.freeze_to(-3)\n",
        "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XphdIfyj3NT2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('third')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D0y8PUT03NT5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.load('third');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P8kZ0gc63NT9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jMhqd-Lh3NT_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.predict(\"I really loved that movie, it was awesome!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qegtrZ673NUF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}