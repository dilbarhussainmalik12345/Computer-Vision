{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CreditCardFraudDetection_using_Smote.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navneetkrc/Colab_fastai/blob/master/Basics/CreditCardFraudDetection_using_Smote.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fn3xlH9ME7xH",
        "colab_type": "text"
      },
      "source": [
        "Based on Analytics Vidhya article on [Medium](https://medium.com/analytics-vidhya/balance-your-data-using-smote-98e4d79fcddb). \n",
        "\n",
        "Also refer to this documentation of [SMOTE](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsDYJigFA1tu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWS_GrcNFTfO",
        "colab_type": "text"
      },
      "source": [
        "##Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGILUmtDFWeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GET THE DATASET FROM THIS LINK\n",
        "##!wget https://www.kaggle.com/mlg-ulb/creditcardfraud/downloads/creditcardfraud.zip/3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBncWmQgF-kt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zySRzwMdGaGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#copy the dataset from gdrive to local colab\n",
        "!cp '/content/drive/My Drive/MLAI_Datasets/creditcardfraud_kaggle.zip' /content/sample_data/ \n",
        "!unzip /content/sample_data/creditcardfraud_kaggle.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi7iv4MTA1t2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('/content/creditcard.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k2KAwFbA1t8",
        "colab_type": "code",
        "outputId": "c923ddbe-9b98-4be2-b223-2e50ee04d8f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pG5u12G6A1uJ",
        "colab_type": "text"
      },
      "source": [
        "## About the Data\n",
        "To quote from Kaggle:\n",
        "\n",
        "\"The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
        "\n",
        "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "P7RY2YDLA1uL",
        "colab_type": "code",
        "outputId": "5550ef7b-4fcf-41ec-a6c2-6e13301f786d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "data['Class'].value_counts().plot.bar()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f698d14bc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD1CAYAAAClSgmzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KVbEKVAA1uT",
        "colab_type": "code",
        "outputId": "b14cf2f6-0dc0-49bd-8f16-b429437a9d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print('Proportion of the classes in the data:')\n",
        "print(data['Class'].value_counts() / len(data))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Proportion of the classes in the data:\n",
            "0    0.998273\n",
            "1    0.001727\n",
            "Name: Class, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEj_b4K5A1ub",
        "colab_type": "text"
      },
      "source": [
        "We will build a simple logistic regression classifer and compare the results for the classifier without SMOTE to with SMOTE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxAD3Va0A1uc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.drop(['Time'], axis = 1)\n",
        "X = np.array(data.loc[:, data.columns != 'Class'])\n",
        "y = np.array(data.loc[:, data.columns == 'Class']).reshape(-1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETrCNnWRA1ui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# standardize the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orBcshj5A1un",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split into training and testing datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 2, shuffle = True, stratify = y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWK4Df0WA1us",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import logistic regression model and accuracy_score metric\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "clf = LogisticRegression(solver = 'lbfgs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHUexHjoA1u0",
        "colab_type": "text"
      },
      "source": [
        "# Without SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAzw0KTVA1u2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit the model\n",
        "clf.fit(X_train, y_train.ravel())\n",
        "\n",
        "# prediction for training dataset\n",
        "train_pred = clf.predict(X_train)\n",
        "\n",
        "# prediction for testing dataset\n",
        "test_pred = clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQaxjF_PA1u-",
        "colab_type": "code",
        "outputId": "2f5e92b5-35a5-4ffd-e15b-6fdf1f3fc610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Accuracy score for Training Dataset = ', accuracy_score(train_pred, y_train))\n",
        "print('Accuracy score for Testing Dataset = ', accuracy_score(test_pred, y_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score for Training Dataset =  0.9991248296824232\n",
            "Accuracy score for Testing Dataset =  0.9992871354549033\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F-JK9lrA1vF",
        "colab_type": "text"
      },
      "source": [
        "Wow! Such high accuracies!\n",
        "\n",
        "You might think that the model has performed exceptionally well. Well, that's not the case. Let us examine the confusion matrix for our predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "VtpuOTeeA1vG",
        "colab_type": "code",
        "outputId": "0bfa1c51-eb9f-44db-ce10-976d646b3b16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print('Confusion Matrix - Training Dataset')\n",
        "print(pd.crosstab(y_train.ravel(), train_pred, rownames = ['True'], colnames = ['Predicted'], margins = True))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix - Training Dataset\n",
            "Predicted       0    1     All\n",
            "True                          \n",
            "0          190457   33  190490\n",
            "1             134  196     330\n",
            "All        190591  229  190820\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OpP0-GwA1vO",
        "colab_type": "text"
      },
      "source": [
        "Now let's interpret the results. \n",
        "\n",
        "134 out of 330 instances which belong to class 1 have been classifed as class 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkkZnbI0A1vP",
        "colab_type": "code",
        "outputId": "34c52304-7f49-4f0b-97c1-897d194583c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "134/330"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.40606060606060607"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIf2Y-eAA1vW",
        "colab_type": "text"
      },
      "source": [
        "That is a whopping 41%! We are classifying 41% of the <b>fraud</b> cases as <b>not fraud</b>. This is going to cost some serious losses to the credit card company. You can observe this similarly in the confusion matrix of the Testing Dataset.\n",
        "\n",
        "The higher accuracy is not due to correct classification. The model has predicted the majority class for almost all the examples. And since about 99.8% of the examples actually belong to this class, it leads to such high accuracy scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK7xr71GA1vX",
        "colab_type": "code",
        "outputId": "a8a0ba27-42eb-4db0-8c31-7e39e112b22f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print('Confusion Matrix - Testing Dataset')\n",
        "print(pd.crosstab(y_test.ravel(), test_pred.ravel(), rownames = ['True'], colnames = ['Predicted'], margins = True))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix - Testing Dataset\n",
            "Predicted      0    1    All\n",
            "True                        \n",
            "0          93815   10  93825\n",
            "1             57  105    162\n",
            "All        93872  115  93987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi40QKODA1vf",
        "colab_type": "text"
      },
      "source": [
        "55 out of 162 instances which belong to class 1 have been classifed as class 0. We are missing about 34% of the fraud cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoXu_oieA1vh",
        "colab_type": "text"
      },
      "source": [
        "# Using SMOTE\n",
        "Researchers have found that balancing the data will to better classification models. We will try balancing our data using SMOTE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuRQlEN7A1vi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9bf4d915-85a1-4038-f437-06cef490c6be"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state = 33)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYd1CvrtA1vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_new, y_train_new = sm.fit_sample(X_train, y_train.ravel())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puhGbwHDA1v3",
        "colab_type": "code",
        "outputId": "bcc66c6e-f859-49f6-fe78-38b603bef060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "# observe that data has been balanced\n",
        "pd.Series(y_train_new).value_counts().plot.bar()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6977c9ec18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD5CAYAAAA5v3LLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZLUZVBIkroMCklSl0EhSeoyKCRJXf8faLBwC3b0iPMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc6FdOh_A1wB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit the model\n",
        "clf.fit(X_train_new, y_train_new)\n",
        "\n",
        "# prediction for Training data\n",
        "train_pred_sm = clf.predict(X_train_new)\n",
        "\n",
        "# prediction for Testing data\n",
        "test_pred_sm = clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "lX2nDmxCA1wH",
        "colab_type": "code",
        "outputId": "09ab36c5-ad9a-4a0b-a95a-b38b7214c776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Accuracy score for Training Dataset = ', accuracy_score(train_pred_sm, y_train_new))\n",
        "print('Accuracy score for Testing Dataset = ', accuracy_score(test_pred_sm, y_test))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score for Training Dataset =  0.9425271667804084\n",
            "Accuracy score for Testing Dataset =  0.9720812452786024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5x5b7DXKA1wP",
        "colab_type": "text"
      },
      "source": [
        "Our accuracy has reduced. But our model has definitely improved. Observe the confusion matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "psjNVX2mA1wY",
        "colab_type": "code",
        "outputId": "d80d6a24-f972-4a8e-eb9a-f1ded4c814d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print('Confusion Matrix - Training Dataset')\n",
        "print(pd.crosstab(y_train_new, train_pred_sm, rownames = ['True'], colnames = ['Predicted'], margins = True))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix - Training Dataset\n",
            "Predicted       0       1     All\n",
            "True                             \n",
            "0          185279    5211  190490\n",
            "1           16685  173805  190490\n",
            "All        201964  179016  380980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsE0umreA1we",
        "colab_type": "code",
        "outputId": "1226ba61-356a-4059-ae12-70945bf2de6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "16685/190490"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08758989973226941"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrIY1nC0A1wk",
        "colab_type": "text"
      },
      "source": [
        "16685 out of 190490 <b>fraud</b> cases have been classified as <b>not fraud</b>. This is a mere 8.7% compared to the previous 41%.\n",
        "\n",
        "A vast improvement!\n",
        "\n",
        "Same is the case with the Testing Dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Wl9C6vOA1wl",
        "colab_type": "code",
        "outputId": "f51dcb89-c5ee-47a9-faad-497b9faeae26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print('Confusion Matrix - Testing Dataset')\n",
        "print(pd.crosstab(y_test.ravel(), test_pred_sm, rownames = ['True'], colnames = ['Predicted'], margins = True))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix - Testing Dataset\n",
            "Predicted      0     1    All\n",
            "True                         \n",
            "0          91213  2612  93825\n",
            "1             12   150    162\n",
            "All        91225  2762  93987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ol1wZAJ4A1ws",
        "colab_type": "code",
        "outputId": "b4b2c2c7-2e4a-42ad-9016-d65b5ee23a96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "12/162"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07407407407407407"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fzpuvPZA1wy",
        "colab_type": "text"
      },
      "source": [
        "Roughly 7.4% of the fraud classes have been classified as not fraud."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUwoquLEA1w0",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion\n",
        "One might argue that the reduced accuracy is an indicator of lower model performance. However, this is not true.\n",
        "\n",
        "Error in prediction can be made in two ways:\n",
        "1. Classifying <b>not fraud</b> as <b>fraud</b>\n",
        "2. Classifying <b>fraud</b> as <b>not fraud</b>\n",
        "\n",
        "It should not be hard to understand that the second error is costlier than the first.\n",
        "\n",
        "The objective of each classification problem is different. So make sure to evaluate each model with respect to its own objective instead of merely judging it on its accuracy."
      ]
    }
  ]
}