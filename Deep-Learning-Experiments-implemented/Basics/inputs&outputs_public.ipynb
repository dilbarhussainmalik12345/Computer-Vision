{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inputs&outputs_public.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navneetkrc/Colab_fastai/blob/master/inputs%26outputs_public.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "amHCfw64LOLW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Colaboratory Imports/Exports Supplemental Tutorial"
      ]
    },
    {
      "metadata": {
        "id": "ysF4OntSLTLg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook could be considered a supplement to the official resource from Colabnoratory for data imports/exports here:\n",
        "[link](https://colab.research.google.com/notebook#fileId=/v2/external/notebooks/io.ipynb)\n",
        "\n",
        "(To be clear I have no afiliation with Google or the Colaboratory team, just trying to help out others getting started with the tool.)\n",
        "\n",
        "Note this notebook is based on a medium post with further explanatory text available here: [link](https://medium.com/@_NicT_/colaboratorys-free-gpu-72ebc9272933)"
      ]
    },
    {
      "metadata": {
        "id": "h1G4npCYLLhA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# General Packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#(Colaboratory environment has tensorflow 1.4.1 installed)\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qtVpwWK6IFV6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Uploading dataset from Local Drive"
      ]
    },
    {
      "metadata": {
        "id": "FDQWK_k3IByG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Once run this will allow you to manually select the path on local drive for file you wish to upload\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for train in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=train, length=len(uploaded[train])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JfquQuk1IJn6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Here is some additional detail for converting the resulting upload into a dataframe\n",
        "from io import BytesIO\n",
        "\n",
        "train_df = pd.read_csv(BytesIO(uploaded[train]), encoding='latin-1')\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oXuhbApVIbyQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Downloading a Keras Model"
      ]
    },
    {
      "metadata": {
        "id": "IWGJrLRzIYmI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#assume we have some trained Keras model we we want to save\n",
        "#save model\n",
        "model.save('modeldownload.h5')\n",
        "\n",
        "#download model\n",
        "from google.colab import files\n",
        "\n",
        "files.download('modeldownload.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9PJp1099Iun5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Uploading a Keras Model"
      ]
    },
    {
      "metadata": {
        "id": "8CnCCyJ7Io8S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Now here is how we can upload a Keras model saved in .h5 format\n",
        "#upload model\n",
        "from google.colab import files\n",
        "\n",
        "uploadedmodel = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K4T5R-VSI1It",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for model in uploadedmodel.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=model, length=len(uploadedmodel[model])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "axwDuMc-KSeA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.models import load_model \n",
        "\n",
        "for model in uploadedmodel.keys():\n",
        "  kerasupload = load_model(model) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z-NBv9vUKWBM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Downloading a dataframe to .CSV file (e.g. for a Kaggle submission)"
      ]
    },
    {
      "metadata": {
        "id": "kxHywO-sKXxZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#assuming we have some submission saved as a dataframe \n",
        "#and we want to download as a .csv for upload to Kaggle\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download('submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vY_FgVF8KgN3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3. Data Operations for Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "sxQPt7PuKhCE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#first step is to authenticate\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZDmgLjL3KkPr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Now we can construct a Drive API client.\n",
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ooan_tDKo66",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For the following approach you will the the \"id\" of the google drive file you wish to download (which is Google Drive meta data, different than the file name). I'm sure there are much cleaner ways to do this, but a quick hack is to use the embedded API on this [Google API page](https://developers.google.com/drive/v2/reference/files/list)\n",
        "(REST v2), which if you simply click the EXECUTE button near bottom of this link without entering any info, it will return a dictionary containing meta-data for every file you have saved in the google drive account you select. If you select all (i.e. control-a) on the output and paste into a word processor you can do a quick control-F string search for the name of the file, and then a few rows above you'll find the \"id\" string.\n",
        "*If any domain experts reading this want to suggest a cleaner way to lookup a file id using the API I'd be happy to update this tutorial."
      ]
    },
    {
      "metadata": {
        "id": "G7ybxvg0KsuX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Uploading dataset from Google Drive\n",
        "\n",
        "\n",
        "# Download the 'train' file from google drive\n",
        "#\n",
        "# Replace the assignment below with your file ID\n",
        "# to download a different file.\n",
        "#\n",
        "# A file ID looks like: 1oCCFFGD10uJIJkff1Hlj4N7hzWXK0TSY\n",
        "\n",
        "file_id = '1oCCFFGD10uJIJkff1Hlj4N7hzWXK0TSY'\n",
        "\n",
        "import io\n",
        "from io import BytesIO\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "request = drive_service.files().get_media(fileId=file_id)\n",
        "downloaded = io.BytesIO()\n",
        "downloader = MediaIoBaseDownload(downloaded, request)\n",
        "done = False\n",
        "while done is False:\n",
        "  status, done = downloader.next_chunk()\n",
        "  if status:\n",
        "      print(\"Download %%%d%%.\" % int(status.progress() * 100))\n",
        "  print(\"Download Complete!\")\n",
        "\n",
        "downloaded.seek(0)\n",
        "#print('Downloaded file contents are: {}'.format(downloaded.read()))\n",
        "\n",
        "df = pd.read_csv(BytesIO(downloaded.read()), encoding='latin-1')\n",
        "df.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}